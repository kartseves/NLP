{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21531a19",
   "metadata": {},
   "source": [
    "### Задание  \n",
    "Взять датасет который прикреплён по ссылке https://www.dropbox.com/s/ykqk49a8avlmnaf/ru_all_split.tar.gz  \n",
    "обучить модель которая будет генерировать заголовки к постам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ad44b",
   "metadata": {},
   "source": [
    "### Чтение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f8b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26eb5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-10569b3db47d67a1\n",
      "Reusing dataset json (C:\\Users\\Kartsev.ES\\.cache\\huggingface\\datasets\\json\\default-10569b3db47d67a1\\0.0.0\\da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0181dc6d5443d2afe4804c0717fbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"./data/ru_all_train.jsonl\",\n",
    "              \"validation\": \"./data/ru_all_val.jsonl\",\n",
    "              \"test\": \"./data/ru_all_test.jsonl\"}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e38811a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'text', 'url', 'timestamp'],\n",
       "        num_rows: 616216\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'text', 'url', 'timestamp'],\n",
       "        num_rows: 34234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'text', 'url', 'timestamp'],\n",
       "        num_rows: 34235\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852f247f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В разных районах Омска появились свои \"Эйфелевы башни\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252d71d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В городе опоры ЛЭП стали необычно подсвечиваться. \\n         Омичи рассказали в соцсетях о необычном способе украсить ночной город: теперь опоры ЛЭП на улицах Ипподромной, 8-й Линии и Масленникова, а также в районе городка Водников подсвечиваются разными цветами. Фотографии опубликовали в группе \"Омск Live\". В комментариях часть омичей скептически отнеслась к такому световому оформлению и отметила, что лучше бы эти средства пустили на освещение городских магистралей или улиц в частном секторе. - И никто не заметил, что в частном секторе ни одного фонаря вообще, в лесу и то проще найти выход, чем в частном секторе Омска ночью,  - пишут омичи. Некоторые пользователи сравнили омские ЛЭП с Эйфелевой башней, так как они теперь тоже подсвечиваются и переливаются с наступлением тёмного времени суток. Отметим, что символ Франции уже украшал омские улицы. Один из них находится в Советском округе в районе Первомайского рынка. Изначально пятиметровая башня была установлена в Выставочном сквере, а затем в 2016 году \"переехала\" в Нефтяники. Над её созданием работал кузнец Константин Бирюков. Второй объект находился в районе турагентства в центре города около остановки \"Улица Рабиновича\". Любовь омичей к Франции и, в частности, к Эйфелевой башне имеет исторические корни. Так, в 1911 году в рамках Первой Западно-Сибирской сельскохозяйственной, лесной и торгово-промышленной выставки в Омске попытались создать уменьшенную копию известной на весь мир башни из вёдер и тазов. Посетители выставки выстраивались в очередь, чтобы посмотреть на омский вариант главного символа Франции.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4453d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_tok(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b190fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11026, 151)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_txt, max_len_tl = max(map(len_tok, dataset['train']['text'])), max(map(len_tok, dataset['train']['title']))\n",
    "max_len_txt, max_len_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11ecd2",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8cf37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_txt, max_len_tl = 100, 25\n",
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c773adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Kartsev.ES\\.cache\\huggingface\\datasets\\json\\default-10569b3db47d67a1\\0.0.0\\da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5\\cache-a8b9446d3198fe2f.arrow\n",
      "Parameter 'function'=<function tokenize at 0x000002478707BC10> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acc374e4157438781d5ced24cd9136d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Kartsev.ES\\.cache\\huggingface\\datasets\\json\\default-10569b3db47d67a1\\0.0.0\\da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5\\cache-d7573fe11dc98030.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98603a32a9c461c8ef924233dbd213a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Kartsev.ES\\.cache\\huggingface\\datasets\\json\\default-10569b3db47d67a1\\0.0.0\\da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5\\cache-1c4d366bb9a9ddbc.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5dadb8c90243f78789edbbf3fb9cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized_input = tokenizer(batch['text'], padding='max_length', truncation=True, max_length=max_len_txt)\n",
    "    tokenized_label = tokenizer(batch['title'], padding='max_length', truncation=True, max_length=max_len_tl)\n",
    "\n",
    "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
    "\n",
    "    return tokenized_input\n",
    "\n",
    "dataset_train = dataset['train'].shuffle(seed=42).select(range(1000)).map(tokenize, batched=True, batch_size=8)\n",
    "dataset_val = dataset['validation'].shuffle(seed=42).select(range(100)).map(tokenize, batched=True, batch_size=8)\n",
    "dataset_test = dataset['test'].shuffle(seed=42).select(range(100)).map(tokenize, batched=True, batch_size=8)\n",
    "\n",
    "dataset_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "dataset_val.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "dataset_test.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26b350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.save_to_disk('./data/ru_all/train')\n",
    "dataset_val.save_to_disk('./data/ru_all/validation')\n",
    "dataset_test.save_to_disk('./data/ru_all/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade84ae",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13251528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35fdd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "271ef369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.decoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e7d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'ru_all/output'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "    prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "    learning_rate=0.00001,\n",
    "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "    save_steps=1000, # How often to save a checkpoint\n",
    "    save_total_limit=1, # Number of maximum checkpoints to save\n",
    "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "    run_name='run_gazeta', # Wandb run name\n",
    "    logging_steps=500, # How often to log loss to wandb\n",
    "    eval_steps=500, # How often to run evaluation on the val_set\n",
    "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "    greater_is_better=False # Best model is the one with the lowest loss, not highest.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581e6f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: timestamp, text, url, title. If timestamp, text, url, title are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Kartsev.ES\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 375\n",
      "C:\\Users\\Kartsev.ES\\Anaconda3\\lib\\site-packages\\transformers\\data\\data_collator.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  batch[k] = torch.tensor([f[k] for f in features])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 12:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=13.289520833333333, metrics={'train_runtime': 759.4579, 'train_samples_per_second': 3.95, 'train_steps_per_second': 0.494, 'total_flos': 398283264000000.0, 'train_loss': 13.289520833333333, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fa6df",
   "metadata": {},
   "source": [
    "### Генерация заголовков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8862fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: | 29 мая правоохранители задержали при получении взятки руководителя одного из медицинских учреждений  Львова . Об этом  сообщает  пресс-служба СБУ. Медик обещал «договориться» с руководством районного военного комиссариата об освобождении от прохождения срочной военной службы по состоянию здоровья. Свои услуги он оценил в 21,5 тысяч гривен. В кабинете заведующего отделением также обнаружили наличные в разной валюте: 150 тысяч гривен, 600 долларов и 400 евро. Правоохранители не разглашают название отделения и фамилию задержанного. Однако по  данным  издания ZAXID.NET, это заведующий 1-м хирургическим отделением Львовской областной клинической больницы Ярослав Зборовский. В случае признания судом его виновным врачу грозит лишение свободы на срок от пяти до десяти лет с лишением права занимать определенные должности и с конфискацией имущества. Напомним, ранее правоохранители  задержали  заведующего отделом трансплантации и хирургии печени Национального института трансплантологии им. Шалимова. Врач требовал от пациента 20 тысяч долларов за операцию по трансплантации печени, проведенную ранее.\n",
      "TITLE: | Обещал договориться с военкоматом: Во Львове задержали известного врача за взятку\n"
     ]
    }
   ],
   "source": [
    "INX = 50\n",
    "print(\"TEXT: | {}\".format(dataset_test['text'][INX]))\n",
    "print(\"TITLE: | {}\".format(dataset_test['title'][INX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1832f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7a14db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output:\n",
      "Правоохранители задержали руководителя одного из медицинских учреждений Львова. Медик обещал «договориться с руководством районного военного комиссариата об освобождении от прохождения срочной\n"
     ]
    }
   ],
   "source": [
    "input_text = dataset_test['text'][INX]\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    source_ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
    "    source_mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids = source_ids,\n",
    "        attention_mask = source_mask, \n",
    "        max_length=50,\n",
    "        num_beams=7,\n",
    "        temperature = 1.3,\n",
    "        repetition_penalty=1, \n",
    "        length_penalty=1, \n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "\n",
    "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(\"\\noutput:\\n\" + pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
