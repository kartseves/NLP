{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62870a89",
   "metadata": {},
   "source": [
    "### Задание  \n",
    "На вебинаре мы говорили что долгое время CNN и RNN архитектуры были конкурирующими, выяснить какая архитектура больше подходит для задачи сентимент анализа на данных с вебинара\n",
    "\n",
    "1. построить свёрточную архитектуру\n",
    "2. построить различные архитектуры с RNN\n",
    "3. построить совместные архитектуры CNN -> RNN и/или (RNN -> CNN)\n",
    "4. сделать выводы что получилось лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e82020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Masking\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740b039",
   "metadata": {},
   "source": [
    "### Чтение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00622c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4506075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d5eb8",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fd473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_replace(word):\n",
    "    newtoken = 'x' * len(word)\n",
    "    return newtoken\n",
    "\n",
    "\n",
    "def clean_token(token, misc):\n",
    "    out_token = token.strip().replace(' ', '')\n",
    "    if token == 'Файл' and 'SpaceAfter=No' in misc:\n",
    "        return None\n",
    "    return out_token\n",
    "\n",
    "\n",
    "def clean_lemma(lemma, pos):\n",
    "    out_lemma = lemma.strip().replace(' ', '').replace('_', '').lower()\n",
    "    if '|' in out_lemma or out_lemma.endswith('.jpg') or out_lemma.endswith('.png'):\n",
    "        return None\n",
    "    if pos != 'PUNCT':\n",
    "        if out_lemma.startswith('«') or out_lemma.startswith('»'):\n",
    "            out_lemma = ''.join(out_lemma[1:])\n",
    "        if out_lemma.endswith('«') or out_lemma.endswith('»'):\n",
    "            out_lemma = ''.join(out_lemma[:-1])\n",
    "        if out_lemma.endswith('!') or out_lemma.endswith('?') or out_lemma.endswith(',') \\\n",
    "                or out_lemma.endswith('.'):\n",
    "            out_lemma = ''.join(out_lemma[:-1])\n",
    "    return out_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d7f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(pipeline, text='Строка', keep_pos=True, keep_punct=False):\n",
    "    entities = {'PROPN'}\n",
    "    named = False\n",
    "    memory = []\n",
    "    mem_case = None\n",
    "    mem_number = None\n",
    "    tagged_propn = []\n",
    "\n",
    "    # обрабатываем текст, получаем результат в формате conllu:\n",
    "    processed = pipeline.process(text)\n",
    "\n",
    "    # пропускаем строки со служебной информацией:\n",
    "    content = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
    "\n",
    "    # извлекаем из обработанного текста леммы, тэги и морфологические характеристики\n",
    "    tagged = [w.split('\\t') for w in content if w]\n",
    "\n",
    "    for t in tagged:\n",
    "        if len(t) != 10:\n",
    "            continue\n",
    "        (word_id, token, lemma, pos, xpos, feats, head, deprel, deps, misc) = t\n",
    "        token = clean_token(token, misc)\n",
    "        lemma = clean_lemma(lemma, pos)\n",
    "        if not lemma or not token:\n",
    "            continue\n",
    "        if pos in entities:\n",
    "            if '|' not in feats:\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "                continue\n",
    "            morph = {el.split('=')[0]: el.split('=')[1] for el in feats.split('|')}\n",
    "            if 'Case' not in morph or 'Number' not in morph:\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "                continue\n",
    "            if not named:\n",
    "                named = True\n",
    "                mem_case = morph['Case']\n",
    "                mem_number = morph['Number']\n",
    "            if morph['Case'] == mem_case and morph['Number'] == mem_number:\n",
    "                memory.append(lemma)\n",
    "                if 'SpacesAfter=\\\\n' in misc or 'SpacesAfter=\\s\\\\n' in misc:\n",
    "                    named = False\n",
    "                    past_lemma = '::'.join(memory)\n",
    "                    memory = []\n",
    "                    tagged_propn.append(past_lemma + '_PROPN ')\n",
    "            else:\n",
    "                named = False\n",
    "                past_lemma = '::'.join(memory)\n",
    "                memory = []\n",
    "                tagged_propn.append(past_lemma + '_PROPN ')\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "        else:\n",
    "            if not named:\n",
    "                if pos == 'NUM' and token.isdigit():  # Заменяем числа на xxxxx той же длины\n",
    "                    lemma = num_replace(token)\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "            else:\n",
    "                named = False\n",
    "                past_lemma = '::'.join(memory)\n",
    "                memory = []\n",
    "                tagged_propn.append(past_lemma + '_PROPN ')\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "\n",
    "    if not keep_punct:\n",
    "        tagged_propn = [word for word in tagged_propn if word.split('_')[1] != 'PUNCT']\n",
    "    if not keep_pos:\n",
    "        tagged_propn = [word.split('_')[0] for word in tagged_propn]\n",
    "    return tagged_propn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32337e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model...\n"
     ]
    }
   ],
   "source": [
    "from ufal.udpipe import Model, Pipeline\n",
    "import wget\n",
    "import os\n",
    "import sys\n",
    "\n",
    "udpipe_model_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
    "udpipe_filename = udpipe_model_url.split('/')[-1]\n",
    "\n",
    "if not os.path.isfile(udpipe_filename):\n",
    "    print('UDPipe model not found. Downloading...', file=sys.stderr)\n",
    "    wget.download(udpipe_model_url)\n",
    "\n",
    "print('\\nLoading the model...', file=sys.stderr)\n",
    "model = Model.load(udpipe_filename)\n",
    "process_pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6f2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(txt, keep_pos):\n",
    "    txt = str(txt)\n",
    "    txt = re.sub(\"@[\\w]*\", ' ', txt)\n",
    "    output = process(process_pipeline, text=txt, keep_pos=keep_pos)\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5170056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'не уезжаааааааать ❤ я тоже не хотеть чтобы ты уезжать'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(df_train['text'][0], keep_pos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7a552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text, keep_pos=False)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text, keep_pos=False)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text, keep_pos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce12f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>не уезжаааааааать ❤ я тоже не хотеть чтобы ты ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt ребята и девчата все в кино вот это любовь ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt кто ненавидеть пробка ретвит rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rt хотеться котлета по-киевска запретный плод</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>босапоп есбоса не бояться мороз и</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  не уезжаааааааать ❤ я тоже не хотеть чтобы ты ...      0\n",
       "1   1  rt ребята и девчата все в кино вот это любовь ...      1\n",
       "2   2                 rt кто ненавидеть пробка ретвит rt      0\n",
       "3   3      rt хотеться котлета по-киевска запретный плод      1\n",
       "4   4                  босапоп есбоса не бояться мороз и      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1b9a4",
   "metadata": {},
   "source": [
    "### Векторизуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ed8ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_length = max([len(i.split()) for i in df_train['text'].values])\n",
    "training_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1216ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(standardize=None, max_tokens=20000, output_sequence_length=training_length)\n",
    "vectorizer.adapt(df_train['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d600aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer(np.array([[s] for s in df_train['text'].values])).numpy()\n",
    "X_valid = vectorizer(np.array([[s] for s in df_val['text'].values])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253713ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_count = len(voc) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b05d1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5c60b",
   "metadata": {},
   "source": [
    "### Моделируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce07db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fdf8c",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ee227",
   "metadata": {},
   "source": [
    "##### SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "717f43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1e08d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 14s 44ms/step - loss: 0.5620 - accuracy: 0.7037 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 14s 44ms/step - loss: 0.4610 - accuracy: 0.7827 - val_loss: 0.5057 - val_accuracy: 0.7440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c415dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 11ms/step - loss: 0.5129 - accuracy: 0.7381\n",
      "\n",
      "\n",
      "Test loss: 0.5128977298736572\n",
      "Test accuracy: 0.7380858063697815\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0cff5",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc38a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a823f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 30s 96ms/step - loss: 0.5587 - accuracy: 0.6953 - val_loss: 0.4880 - val_accuracy: 0.7522\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 30s 93ms/step - loss: 0.4669 - accuracy: 0.7754 - val_loss: 0.4866 - val_accuracy: 0.7498\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 30s 94ms/step - loss: 0.4411 - accuracy: 0.7901 - val_loss: 0.4901 - val_accuracy: 0.7581\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd26371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 21ms/step - loss: 0.4948 - accuracy: 0.7560\n",
      "\n",
      "\n",
      "Test loss: 0.4948217272758484\n",
      "Test accuracy: 0.7560287714004517\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a58fdf",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40622b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(GRU(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a3f68a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 26s 80ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6934 - val_accuracy: 0.5049\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 25s 79ms/step - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6932 - val_accuracy: 0.5049\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 25s 80ms/step - loss: 0.6931 - accuracy: 0.5070 - val_loss: 0.6931 - val_accuracy: 0.5049\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 26s 81ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cd87544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6931 - accuracy: 0.5047\n",
      "\n",
      "\n",
      "Test loss: 0.693148136138916\n",
      "Test accuracy: 0.5047392249107361\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be0de6",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1497ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "584d0a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 10s 32ms/step - loss: 0.5913 - accuracy: 0.6897 - val_loss: 0.5114 - val_accuracy: 0.7539\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 11s 34ms/step - loss: 0.4971 - accuracy: 0.7764 - val_loss: 0.4896 - val_accuracy: 0.7637\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 11s 34ms/step - loss: 0.4521 - accuracy: 0.8053 - val_loss: 0.4888 - val_accuracy: 0.7636\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 11s 34ms/step - loss: 0.4101 - accuracy: 0.8299 - val_loss: 0.5121 - val_accuracy: 0.7661\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c870e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.7596\n",
      "\n",
      "\n",
      "Test loss: 0.5144764184951782\n",
      "Test accuracy: 0.7596437931060791\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12231bb4",
   "metadata": {},
   "source": [
    "#### CNN + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1093a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9866dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Reshape with the first argument being the number of filter in your last conv layer\n",
    "model.add(Reshape((10, -1)))\n",
    "# Just write this Permute after, its complicated why\n",
    "model.add(Permute((2, 1)))\n",
    "\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4578b0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 12s 36ms/step - loss: 0.5466 - accuracy: 0.7082 - val_loss: 0.4769 - val_accuracy: 0.7618\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 11s 36ms/step - loss: 0.4348 - accuracy: 0.7976 - val_loss: 0.4734 - val_accuracy: 0.7668\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 11s 35ms/step - loss: 0.3682 - accuracy: 0.8376 - val_loss: 0.4977 - val_accuracy: 0.7665\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "894bfa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7641\n",
      "\n",
      "\n",
      "Test loss: 0.5034821033477783\n",
      "Test accuracy: 0.7640523910522461\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a688a6",
   "metadata": {},
   "source": [
    "__ВЫВОД:__ Наблюдаем, что из всех рассмотренных моделей комбинация архитектур CNN + RNN показывает лучший результат"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
